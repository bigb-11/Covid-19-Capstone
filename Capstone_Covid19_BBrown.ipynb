{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define the connection parameters\n",
    "server = 'B-SURFACE\\\\SQLEXPRESS'  # Note the double backslashes for escaping\n",
    "database = 'Covid19Capstone'    # Replace with your actual database name\n",
    "driver = 'SQL Server'\n",
    "\n",
    "# Create the connection string using Windows Authentication\n",
    "connection_string = f\"mssql+pyodbc://@{server}/{database}?driver={driver}&trusted_connection=yes\"\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Query Data\n",
    "\n",
    "query = \"SELECT * FROM Kaggle_Sirio_Libanes_ICU_Prediction\"\n",
    "data = pd.read_sql(query, engine)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Categorical Data to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Age_Percentile, Window  to Float\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Display first few rows of original data\n",
    "print(\"Original Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Identify Categorical Columns\n",
    "categorical_columns = ['AGE_PERCENTIL', 'WINDOW']\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to 'AGE_PERCENTIL' column\n",
    "data['Age_Encoded'] = le.fit_transform(data['AGE_PERCENTIL'])\n",
    "print(\"\\nDataFrame after Label Encoding 'AGE_PERCENTIL':\")\n",
    "print(data.head())\n",
    "\n",
    "# Apply label encoding to 'WINDOW' column\n",
    "data['Window_Encoded'] = le.fit_transform(data['WINDOW'])\n",
    "print(\"\\nDataFrame after Label Encoding 'WINDOW':\")\n",
    "print(data['WINDOW'])\n",
    "print(data['Window_Encoded'])\n",
    "\n",
    "#Drop Categorical Columns\n",
    "data.drop(columns=['WINDOW', 'AGE_PERCENTIL'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imputation\n",
    "from sklearn.impute import SimpleImputer, KNNImputer  # This means 'k' number of nearest neighbors\n",
    "\n",
    "# Impute with median\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "data_median_imputed = pd.DataFrame(imputer_median.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Initialize the KNNImputer\n",
    "imputer_knn = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Perform the imputation and Convert the resulting numPy array back to a dataframe.\n",
    "data_knn_imputed = pd.DataFrame(imputer_knn.fit_transform(data_knn_imputed), columns=data_knn_imputed.columns)\n",
    "\n",
    "# Display the first few rows of the imputed data\n",
    "print(\"Imputed data (KNN):\")\n",
    "print(data_knn_imputed.head())\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(\"Missing values after imputation (KNN):\")\n",
    "print(data_knn_imputed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Data Where Target Variable ICU = 1\n",
    "Per Kaggle: \"Beware NOT to use data when the target variable is present, as it is unknown the order of the event (maybe the target event happened before the results were obtained). They were kept there so we can grow this dataset in other outcomes [later] on.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_VISIT_IDENTIFIER', 'AGE_ABOVE65', 'GENDER',\n",
      "       'DISEASE_GROUPING_1', 'DISEASE_GROUPING_2', 'DISEASE_GROUPING_3',\n",
      "       'DISEASE_GROUPING_4', 'DISEASE_GROUPING_5', 'DISEASE_GROUPING_6', 'HTN',\n",
      "       ...\n",
      "       'OXYGEN_SATURATION_DIFF', 'BLOODPRESSURE_DIASTOLIC_DIFF_REL',\n",
      "       'BLOODPRESSURE_SISTOLIC_DIFF_REL', 'HEART_RATE_DIFF_REL',\n",
      "       'RESPIRATORY_RATE_DIFF_REL', 'TEMPERATURE_DIFF_REL',\n",
      "       'OXYGEN_SATURATION_DIFF_REL', 'ICU', 'Age_Encoded', 'Window_Encoded'],\n",
      "      dtype='object', length=231)\n"
     ]
    }
   ],
   "source": [
    "print(data_knn_imputed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\britt\\AppData\\Local\\Temp\\ipykernel_20572\\1832450635.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned.drop(columns=['ICU_PREV'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Sort the dataframe by PATIENT_VISIT_IDENTIFIER and WINDOW\n",
    "data_knn_imputed.sort_values(by=['PATIENT_VISIT_IDENTIFIER', 'Window_Encoded'] , inplace=True)\n",
    "\n",
    "# Shift the ICU column by 1 within each PATIENT_VISIT_IDENTIFIER group\n",
    "data_knn_imputed['ICU_PREV'] = data_knn_imputed.groupby('PATIENT_VISIT_IDENTIFIER')['ICU'].shift(-1)\n",
    "\n",
    "# Drop rows where ICU was 1 in the previous window\n",
    "df_cleaned = data_knn_imputed[data_knn_imputed['ICU_PREV'] != 1]\n",
    "\n",
    "# Drop the ICU_PREV column as it's no longer needed\n",
    "df_cleaned.drop(columns=['ICU_PREV'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442, 231)\n",
      "Index(['PATIENT_VISIT_IDENTIFIER', 'AGE_ABOVE65', 'GENDER',\n",
      "       'DISEASE_GROUPING_1', 'DISEASE_GROUPING_2', 'DISEASE_GROUPING_3',\n",
      "       'DISEASE_GROUPING_4', 'DISEASE_GROUPING_5', 'DISEASE_GROUPING_6', 'HTN',\n",
      "       ...\n",
      "       'OXYGEN_SATURATION_DIFF', 'BLOODPRESSURE_DIASTOLIC_DIFF_REL',\n",
      "       'BLOODPRESSURE_SISTOLIC_DIFF_REL', 'HEART_RATE_DIFF_REL',\n",
      "       'RESPIRATORY_RATE_DIFF_REL', 'TEMPERATURE_DIFF_REL',\n",
      "       'OXYGEN_SATURATION_DIFF_REL', 'ICU', 'Age_Encoded', 'Window_Encoded'],\n",
      "      dtype='object', length=231)\n"
     ]
    }
   ],
   "source": [
    "from pandas import option_context\n",
    "with option_context('display.max_rows', 10, 'display.max_columns', 231):\n",
    "    pass\n",
    "\n",
    "print(df_cleaned.shape)\n",
    "print(df_cleaned.columns)\n",
    "# print(df_cleaned.head)\n",
    "\n",
    "df_cleaned.to_csv('Capstone_Cleaned_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.972318339100346\n",
      "Logistic Regression Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98       251\n",
      "         1.0       0.94      0.84      0.89        38\n",
      "\n",
      "    accuracy                           0.97       289\n",
      "   macro avg       0.96      0.92      0.94       289\n",
      "weighted avg       0.97      0.97      0.97       289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data\n",
    "X = df_cleaned.drop(columns=['ICU']) #input\n",
    "y = df_cleaned['ICU'] #output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print('Logistic Regression Accuracy:', accuracy_score(y_test, y_pred_log))\n",
    "print('Logistic Regression Report:\\n', classification_report(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9411764705882353\n",
      "Decision Tree Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       251\n",
      "         1.0       0.76      0.82      0.78        38\n",
      "\n",
      "    accuracy                           0.94       289\n",
      "   macro avg       0.86      0.89      0.88       289\n",
      "weighted avg       0.94      0.94      0.94       289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dec = dt.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print('Decision Tree Accuracy:', accuracy_score(y_test, y_pred_dec))\n",
    "print('Decision Tree Report:\\n', classification_report(y_test, y_pred_dec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9653979238754326\n",
      "Random Forest Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98       251\n",
      "         1.0       0.89      0.84      0.86        38\n",
      "\n",
      "    accuracy                           0.97       289\n",
      "   macro avg       0.93      0.91      0.92       289\n",
      "weighted avg       0.96      0.97      0.96       289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print('Random Forest Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('Random Forest Report:\\n', classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8685121107266436\n",
      "SVM Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93       251\n",
      "         1.0       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.87       289\n",
      "   macro avg       0.43      0.50      0.46       289\n",
      "weighted avg       0.75      0.87      0.81       289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\britt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\britt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Support Vector Machine\n",
    "svc = SVC(kernel='rbf', probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm = svc.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print('SVM Accuracy:', accuracy_score(y_test, y_pred_svm))\n",
    "print('SVM Report:\\n', classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Naive Bayes\n",
    "Bayes theorem states the probability of some event B occurring provided the prior knowledge of another event(s) A, given that B is dependent on event A (even partially). Naive Bayes' assumes feature independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9411764705882353\n",
      "Naive Bayes Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       251\n",
      "         1.0       0.86      0.66      0.75        38\n",
      "\n",
      "    accuracy                           0.94       289\n",
      "   macro avg       0.91      0.82      0.86       289\n",
      "weighted avg       0.94      0.94      0.94       289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print('Naive Bayes Accuracy:', accuracy_score(y_test, y_pred_nb))\n",
    "print('Naive Bayes Report:\\n', classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Smote to Oversample the minor class (yes) - (Synthetic Minority Over-sampling Technique) \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to your training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Re-initialize the models (if needed)\n",
    "logreg_model_smote = LogisticRegression(max_iter=2000)\n",
    "dt_model_smote = DecisionTreeClassifier()\n",
    "\n",
    "# Re-train Logistic Regression with SMOTE data\n",
    "logreg_model_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Re-train Decision Tree Classifier with SMOTE data\n",
    "dt_model_smote.fit(X_train_smote, y_train_smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrained Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier (SMOTE) Accuracy: 0.9446366782006921\n",
      "Decision Tree Classifier (SMOTE) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       251\n",
      "         1.0       0.79      0.79      0.79        38\n",
      "\n",
      "    accuracy                           0.94       289\n",
      "   macro avg       0.88      0.88      0.88       289\n",
      "weighted avg       0.94      0.94      0.94       289\n",
      "\n",
      "Logistic Regression (SMOTE) Accuracy: 0.9584775086505191\n",
      "Logistic Regression (SMOTE) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98       251\n",
      "         1.0       0.80      0.92      0.85        38\n",
      "\n",
      "    accuracy                           0.96       289\n",
      "   macro avg       0.89      0.94      0.91       289\n",
      "weighted avg       0.96      0.96      0.96       289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_predictions_smote = dt_model_smote.predict(X_test)\n",
    "logreg_predictions_smote = logreg_model_smote.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "dt_accuracy_smote = accuracy_score(y_test, dt_predictions_smote)\n",
    "logreg_accuracy_smote = accuracy_score(y_test, logreg_predictions_smote)\n",
    "\n",
    "# Generate classification reports\n",
    "dt_report_smote = classification_report(y_test, dt_predictions_smote)\n",
    "logreg_report_smote = classification_report(y_test, logreg_predictions_smote)\n",
    "\n",
    "print(\"Decision Tree Classifier (SMOTE) Accuracy:\", dt_accuracy_smote)\n",
    "print(\"Decision Tree Classifier (SMOTE) Classification Report:\\n\", dt_report_smote)\n",
    "\n",
    "print(\"Logistic Regression (SMOTE) Accuracy:\", logreg_accuracy_smote)\n",
    "print(\"Logistic Regression (SMOTE) Classification Report:\\n\", logreg_report_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
